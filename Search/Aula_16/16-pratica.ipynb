{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 16 - Pontos de Interesse e casamento de imagens\n",
    "\n",
    "Neste roteiro iremos estudar o comportamento de algoritmos de detecção e descrição de pontos de interesse e como usá-los para fazer uma versão simplificada de um algoritmo de busca de imagens. \n",
    "\n",
    "## AVISO\n",
    "\n",
    "Existe uma grande quantidade de tutoriais online com códigos de exemplo para este problema, mas **seu uso não é recomendado**. Além de muitos conterem material claramente desatualizado, muitos tutoriais encorajam um simples copiar-colar de código sem levar em conta as *ideias que o motivaram*. Nesta atividade recomendamos usar, como material complementar, a [documentação do OpenCV em Python](https://docs.opencv.org/3.4.3/d6/d00/tutorial_py_root.html) sobre [Feature Detection and Description](https://docs.opencv.org/3.4.3/db/d27/tutorial_py_table_of_contents_feature2d.html).\n",
    "\n",
    "## Banco de imagens para a aula\n",
    "\n",
    "Neste primeiro roteiro iremos trabalhar com um conjunto de imagens que não é focado exclusivamente em recuperação de informação, mas sim em detecção de objetos. Iremos usar a versão de 2005 do [Pascal VOC Challenge](http://host.robots.ox.ac.uk/pascal/VOC/databases.html#VOC2005_1), que você já deve ter baixado. Se não baixou ainda, o download não é pequeno (465Mb) então deixe baixando e prossiga com o roteiro. \n",
    "\n",
    "\n",
    "## Pesquisa\n",
    "\n",
    "1. Detectores de pontos de interesse são classificados, basicamente, em três tipos. Quais são eles e quais características locais das imagens são exploradas?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Edge Detection: identificação de pontos da imagem nos quais o brilho e/ou cor mudam de modo abrupto\n",
    "Corner detection: detecção da intersecção de duas arestas \n",
    "Blob detection: detecção de regiões que possuem cor/briho difententes das outras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. O OpenCV possui diversos algoritmos para detecção e descrição de pontos de interesse. Faça uma lista deles abaixo (deixando bem claro qual método faz detecção, extração ou ambos). Coloque o nome do método, a classe que o implementa e seu tipo (para os detectores somente)."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "1) Harris Corner Detection: detecção\n",
    "2) Shi-Tomasi Corner Detector & Good Features to Track: detecção\n",
    "3) Scale-Invariant Feature Transform: detecção\n",
    "4) Speeded-Up Robust Features : detecção e descrição\n",
    "5) Binary Robust Independent Elementary Features: descrição\n",
    "6) FAST Algorithm for Corner Detection: detecção\n",
    "7) ORB (Oriented FAST and Rotated BRIEF): detecção e descrição"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Escolha um dos métodos acima e descreva sua ideia básica no campo abaixo. Você deve indicar em qual artigo ele foi proposto, quais suas características marcantes em relação aos outros métodos e uma aplicação em que este descritor obteve resultados relavantes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementação\n",
    "\n",
    "Vamos agora implementar o método de similaridade de imagens descrito na aula expositiva, resumido abaixo. Você receberá como entrada uma imagem de busca $Q$ e um banco de imagens $\\{F^i\\}_{i=0}^N$ contendo $N$ imagens.\n",
    "\n",
    "1. Detecte os pontos de interesse e extraia os descritores $\\{q_j\\}$ de $Q$\n",
    "2. Para cada imagem $F^i$:\n",
    "    - Detecte os pontos de interesse e extraia os descritores $\\{F_k\\}$ de $F^i$ \n",
    "    - Para cada descritor $q_j$, verifique se existe um descritor $F_k$ que casa com ele\n",
    "    - Calcule a proporção de descritores de $Q$ que casaram com descritores de $F^i$ e use este valor como a similaridade entre as duas imagens.\n",
    "    \n",
    "3. Retorne as 5 imagens com maior similaridade;\n",
    "\n",
    "### Exercício\n",
    "\n",
    "Antes de continuar, leia com atenção o algoritmo acima e pense: como você organizaria seu código para implementá-lo? Quais funções auxiliares criaria e quais argumentos cada uma receberia? Supondo que todas essas funções auxiliares já foram implementadas, como seria o código principal de seu programa?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "list_desc = find_features(img) » recebe a imagem e devolve os descritores\n",
    "\n",
    "bool = compare_descriptors(qj, Fk) » verifica se um descritor casa com outro\n",
    "\n",
    "prop = calculate_proportion(list_qj, list_Fk) » calcula a proporção de descritores de Q que casaram com os descritores F e retorna a propria proporção"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def find_features(img):\n",
    "    # Initiate ORB detector\n",
    "    orb = cv.ORB_create()\n",
    "    # find the keypoints with ORB\n",
    "    kp = orb.detect(img,None)\n",
    "    # compute the descriptors with ORB\n",
    "    kp, des = orb.compute(img, kp)\n",
    "    return des\n",
    "\n",
    "def compare_descriptors(qj, Fk):\n",
    "    #casa descritor\n",
    "    pass\n",
    "    \n",
    "def calculate_proportion(list_d1, list_d2):\n",
    "    prop = 0\n",
    "    for i in range(len(list_d1)):\n",
    "        for j in range(len(list_d2)):\n",
    "            if (compare_descriptors(list_d1[i], list_d2[j])):\n",
    "                prop +=1\n",
    "    return prop/(len(list_d1))\n",
    "\n",
    "prop_dict = {}\n",
    "actual_descriptor = find_features(img)\n",
    "for image_path in dataset:\n",
    "    image = cv.imread(image_path)\n",
    "    actual_dataset_descriptor = find_features(image)\n",
    "    prop = calculate_proportion(actual_descriptor, actual_dataset_descriptor)\n",
    "    prop_dict[image_path] = prop\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extração e descrição de pontos de interesse\n",
    "\n",
    "A detecção e descrição de pontos de interesse é um processo que será repetido várias vezes nesta e na próxima atividade. Na parte de pesquisa você identificou alguns métodos de extração e descrição de pontos de interesse. Selecione um de cada tipo (ou um que faça ambos) e crie uma função que recebe uma imagem e retorna os descritores dela. Mesmo que a função seja muito pequena (duas ou três linhas), é uma boa fazê-lo para deixar o programa principal mais legível e parecido com o algoritmo descrito em linguagem natural. \n",
    "\n",
    "OBS: os exercícios foram testados usando o descritor *ORB*. Você pode usar outro nos seus testes, mas pode ter que adaptar parte do código. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def calc_dist(list1, list2):\n",
    "    dist = 0\n",
    "    string1 = '{}'.format(list1)\n",
    "    string2 = '{}'.format(list2)\n",
    "    for j in range(len(string1)):\n",
    "        if(string1[j] != string2[j]):\n",
    "            dist +=1\n",
    "    return dist\n",
    "    \n",
    "\n",
    "def reciprocal_match(desc1, desc2):\n",
    "    matches = []\n",
    "    for i in range (len(desc1)):\n",
    "        min_dist = calc_dist(desc1[i], desc2[0])\n",
    "        index2 = 0\n",
    "        for j in range(1, len(desc2)):\n",
    "            min_actual = calc_dist(desc1[i], desc2[j])\n",
    "            if(min_actual < min_dist):\n",
    "                min_dist = min_actual\n",
    "                index2 = j\n",
    "        min_dist2 = calc_dist(desc1[0], desc2[index2])\n",
    "        index1 = 0\n",
    "        for k in range (len(desc1)):\n",
    "            min_actual = calc_dist(desc2[index2], desc1[k])\n",
    "            if(min_actual < min_dist2):\n",
    "                min_dist2 = min_actual\n",
    "                index1 = k\n",
    "        if(index1 == i):\n",
    "            matches.append(cv.DMatch(index1, index2, min_dist))\n",
    "    return matches\n",
    "\n",
    "\n",
    "def find_features(img):\n",
    "    # Initiate ORB detector\n",
    "    orb = cv.ORB_create(nfeatures=50)\n",
    "    # find the keypoints with ORB\n",
    "    kp = orb.detect(img,None)\n",
    "    # compute the descriptors with ORB\n",
    "    kp, des = orb.compute(img, kp)\n",
    "    return kp, des\n",
    "\n",
    "def compare_descriptors(qj, Fk):\n",
    "    bf = cv.BFMatcher(cv.NORM_HAMMING, crossCheck=True)\n",
    "    matches = bf.match(qj,Fk)\n",
    "    return matches\n",
    "\n",
    "def calculate_proportion(list_d1, list_d2):    \n",
    "    matches = compare_descriptors(list_d1, list_d2)\n",
    "    return len(matches)/len(list_d1)\n",
    "\n",
    "def compare_images(img1, img2):\n",
    "    kp1, actual_descriptor = find_features(img1)\n",
    "    kp2, actual_dataset_descriptor = find_features(img2)\n",
    "    prop = calculate_proportion(actual_descriptor, actual_dataset_descriptor)\n",
    "    print(prop)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Teste sua função usando a imagem *cachorro.jpg*. Você pode visualilzar os pontos de interesse usando a função [`cv2.drawKeypoints()`](https://docs.opencv.org/3.4.3/d4/d5d/group__features2d__draw.html#gab958f8900dd10f14316521c149a60433)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "img = cv.imread(\"cachorro.jpg\")\n",
    "kp, des = find_features(img)\n",
    "img2 = cv.drawKeypoints(img, kp, None, color=(0,255,0), flags=0)\n",
    "img2 = cv.cvtColor(img2, cv.COLOR_BGR2RGB);\n",
    "plt.imshow(img2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Casamento de pontos de interesse\n",
    "\n",
    "O OpenCV possui duas técnicas de casamento de pontos de interesse implementadas: `cv2.BFMatcher` e `cv2.FlannBasedMatcher`. Para exercitar a compreensão do algoritmo de casamento vamos implementar nossa própria versão do `BFMatcher`. \n",
    "\n",
    "----------\n",
    "\n",
    "Sim, no projeto vocês podem usar as implementações do OpenCV. Na próxima aula iremos usar o `FlannBasedMatcher` e usar um novo critério para casamento de pontos. \n",
    "\n",
    "----------\n",
    "\n",
    "#### Exercício:\n",
    "\n",
    "Implemente uma função `reciprocal_math(desc1, desc2)` que faz o casamento dos descritores passados como argumento. Um par de descritores $(d^1_i, d^2_j)$ *casa* se $dist(d^1_i, d^2_j) < dist(d^1_k, d^2_j), k\\neq i$ **E** $dist(d^1_i, d^2_j) < dist(d^1_i, d^2_k), k\\neq j$. Como função de distância tem duas opções:\n",
    "\n",
    "1. Se os dados computados pelo seu descritor forem um vetor de float você pode usar a norma $\\ell_2$ da diferença dos vetores\n",
    "\n",
    "$$\n",
    "dist(d^1_i, d^2_j) = ||d^1_i - d^2_j||_2\n",
    "$$\n",
    "\n",
    "2. Se os dados computados forem um vetor de bits você deve usar como distância o número de bits diferentes entre as duas strings. Isto pode ser feito, em Python, em três passos:\n",
    "    1. Vetores de bits são representados por vetores de inteiros de 8 bits. Para cada um dos inteiros:\n",
    "    2. Converta-o para uma string contendo sua representação em binário usando a função `format`.\n",
    "    3. Conte o número de caracteres diferentes nas strings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para que nossa função `reciprocal_match` seja integrada ao OpenCV precisamos retornar uma lista de objetos do tipo `cv2.DMatch`. Para criar um objeto deste tipo basta chamar o construtor com três parâmetros:\n",
    "\n",
    "1. índice $i$ do descritor da imagem de pesquisa\n",
    "2. índice $j$ do descritor da imagem do banco\n",
    "3. distância calculada como a fórmula acima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def find_features(img):\n",
    "    # Initiate ORB detector\n",
    "    orb = cv.ORB_create()\n",
    "    # find the keypoints with ORB\n",
    "    kp = orb.detect(img,None)\n",
    "    # compute the descriptors with ORB\n",
    "    kp, des = orb.compute(img, kp)\n",
    "    return kp, des\n",
    "\n",
    "def calc_dist(list1, list2):\n",
    "    dist = 0\n",
    "    for i in range(len(list1)):\n",
    "        string1 = '{:08b}'.format(list1[i])\n",
    "        string2 = '{:08b}'.format(list2[i])\n",
    "        for j in range(len(string1)):\n",
    "            if(string1[j] != string2[j]):\n",
    "                dist +=1\n",
    "    return dist\n",
    "    \n",
    "\n",
    "def reciprocal_match(desc1, desc2):\n",
    "    matches = []\n",
    "    for i in range (len(desc1)):\n",
    "        min_dist = calc_dist(desc1[i], desc2[0])\n",
    "        index2 = 0\n",
    "        for j in range(1, len(desc2)):\n",
    "            min_actual = calc_dist(desc1[i], desc2[j])\n",
    "            if(min_actual < min_dist):\n",
    "                min_dist = min_actual\n",
    "                index2 = j\n",
    "        min_dist2 = calc_dist(desc1[0], desc2[index2])\n",
    "        index1 = 0\n",
    "        for k in range (len(desc1)):\n",
    "            min_actual = calc_dist(desc2[index2], desc1[k])\n",
    "            if(min_actual < min_dist2):\n",
    "                min_dist2 = min_actual\n",
    "                index1 = k\n",
    "        if(index1 == i):\n",
    "            matches.append(cv.DMatch(index1, index2, min_dist))\n",
    "    return matches\n",
    "\n",
    "def avg_matcher(matches):\n",
    "    if(len(matches) != 0):\n",
    "        print(f\"Média: {sum([matcher.distance for matcher in matches])/len(matches)}\")\n",
    "    v = [matcher.distance for matcher in matches]\n",
    "    print(f\"Média 100: {np.average(np.sort(v)[0:100])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos analisar os resultados dessa função de casamento usando as imagens *cachorro2.png* e *cidade.jpeg*. Extraia os descritores de ambas e faça um casamento com os descritores extraídos no exercício anterior. Para mostrar os resultados você pode usar a função [`cv2.DrawMatches()`](https://docs.opencv.org/3.4.3/d4/d5d/group__features2d__draw.html#ga7421b3941617d7267e3f2311582f49e1). Mostre também a distância média dos casamentos encontrados. Para comparar, mostre a distância média dos 100 casamentos com menor distância para cada imagem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = cv.imread(\"cachorro.jpg\")\n",
    "img2 = cv.imread(\"cachorro2.jpg\")\n",
    "kp1, actual_descriptor = find_features(img1)\n",
    "kp2, actual_dataset_descriptor = find_features(img2)\n",
    "\n",
    "matches = reciprocal_match(actual_descriptor, actual_dataset_descriptor)\n",
    "out = cv.drawMatches(img1, kp1, img2, kp2, matches, None)\n",
    "avg_matcher(matches)\n",
    "plt.imshow(out)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "img1 = cv.imread(\"cachorro.jpg\")\n",
    "img2 = cv.imread(\"cidade.jpeg\")\n",
    "kp1, actual_descriptor = find_features(img1)\n",
    "kp2, actual_dataset_descriptor = find_features(img2)\n",
    "\n",
    "matches = reciprocal_match(actual_descriptor, actual_dataset_descriptor)\n",
    "out = cv.drawMatches(img1, kp1, img2, kp2, matches, None)\n",
    "avg_matcher(matches)\n",
    "plt.imshow(out)\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em ambos os casos houveram muitos casamentos, mas a distância média foi (deveria ser) menor no caso do cachorro. Modifique a função `reciprocal_match` para receber um terceiro argumento que representa a distância máxima entre descritores para que o casamento seja válido. Determine, então, um valor que torne o número de descritores encontrados nas imagens acima significativamente diferente. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reciprocal_match2(desc1, desc2, max_dist):\n",
    "    matches = []\n",
    "    for i in range (len(desc1)):\n",
    "        min_dist = calc_dist(desc1[i], desc2[0])\n",
    "        index2 = 0\n",
    "        for j in range(1, len(desc2)):\n",
    "            min_actual = calc_dist(desc1[i], desc2[j])\n",
    "            if(min_actual < min_dist):\n",
    "                min_dist = min_actual\n",
    "                index2 = j\n",
    "        min_dist2 = calc_dist(desc1[0], desc2[index2])\n",
    "        index1 = 0\n",
    "        for k in range (len(desc1)):\n",
    "            min_actual = calc_dist(desc2[index2], desc1[k])\n",
    "            if(min_actual < min_dist2):\n",
    "                min_dist2 = min_actual\n",
    "                index1 = k\n",
    "        if(index1 == i):\n",
    "            if(min_dist <= max_dist):\n",
    "                matches.append(cv.DMatch(index1, index2, min_dist))\n",
    "    return matches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teste o valor determinado com a imagem *cachorro3.jpg*. Comente os resultados obtidos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = cv.imread(\"cachorro3.jpg\")\n",
    "img2 = cv.imread(\"cachorro.jpg\")\n",
    "kp1, actual_descriptor = find_features(img1)\n",
    "kp2, actual_dataset_descriptor = find_features(img2)\n",
    "\n",
    "matches = reciprocal_match2(actual_descriptor, actual_dataset_descriptor, 55)\n",
    "out = cv.drawMatches(img1, kp1, img2, kp2, matches, None)\n",
    "avg_matcher(matches)\n",
    "plt.imshow(out)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Juntando tudo\n",
    "\n",
    "Use as funções acima para calcular a similaridade entre duas imagens, definida como a proporção de pontos casados em relação ao número de pontos da imagem de pesquisa $Q$. Sua função deve se chamar `similarity_proportion_matches` e deve receber duas imagens como entrada e retornar um número entre $0$ (totalmente diferente) e $1$ (idênticas). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_proportion(list_d1, list_d2):    \n",
    "    matches = reciprocal_match2(list_d1, list_d2, 55)\n",
    "    return len(matches), len(list_d1)\n",
    "\n",
    "def similarity_proportion_matches(img1, img2):\n",
    "    kp1, actual_descriptor = find_features(img1)\n",
    "    kp2, actual_dataset_descriptor = find_features(img2)\n",
    "    prop, l = calculate_proportion(actual_descriptor, actual_dataset_descriptor)\n",
    "    print(prop/l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rode sua função com as imagens usadas no exercício anterior e verifique se sua função de similaridade ordenaria as imagens de maneira satisfatória."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Cachorro: cachorro\")\n",
    "img1 = cv.imread(\"cachorro.jpg\")\n",
    "# img2 = cv.imread(\"cidade.jpeg\")\n",
    "img2 = cv.imread(\"cachorro.jpg\")\n",
    "similarity_proportion_matches(img1, img2)\n",
    "print()\n",
    "\n",
    "print(\"Cachorro: cachorro2\")\n",
    "img1 = cv.imread(\"cachorro.jpg\")\n",
    "# img2 = cv.imread(\"cidade.jpeg\")\n",
    "img2 = cv.imread(\"cachorro2.jpg\")\n",
    "similarity_proportion_matches(img1, img2)\n",
    "print()\n",
    "\n",
    "print(\"Cachorro: cachorro3\")\n",
    "img1 = cv.imread(\"cachorro.jpg\")\n",
    "# img2 = cv.imread(\"cidade.jpeg\")\n",
    "img2 = cv.imread(\"cachorro3.jpg\")\n",
    "similarity_proportion_matches(img1, img2)\n",
    "print()\n",
    "\n",
    "print(\"Cachorro: cidade\")\n",
    "img1 = cv.imread(\"cachorro.jpg\")\n",
    "# img2 = cv.imread(\"cidade.jpeg\")\n",
    "img2 = cv.imread(\"cidade.jpeg\")\n",
    "similarity_proportion_matches(img1, img2)\n",
    "print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testes e avaliação crítica dos resultados\n",
    "\n",
    "Você deve agora executar seu código nas imagens da base de dados sugerida no começo do roteiro. São presentes apenas imagens com 4 objetos diferentes: pessoas, motos, bicicletas e carros. Selecione uma imagem de cada tipo e mostre as 3 imagens com maior similaridade para cada uma delas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random \n",
    "\n",
    "\n",
    "PATH = '../BVW/PNGImages/'\n",
    "\n",
    "dirs = os.listdir(PATH)\n",
    "\n",
    "DATASET = []\n",
    "for directory in dirs:\n",
    "    if('.' not in directory):\n",
    "        actual_path = PATH + directory + '/'\n",
    "        dir_images = os.listdir(actual_path)\n",
    "        for path_images in dir_images:\n",
    "            total_path = actual_path + path_images\n",
    "#             print(total_path)\n",
    "            DATASET.append(total_path)\n",
    "\n",
    "def calculate_proportion(list_d1, list_d2):    \n",
    "    matches = reciprocal_match2(list_d1, list_d2, 55)\n",
    "    return len(matches)/len(list_d1)\n",
    "\n",
    "def compare_all_images(img, dataset):\n",
    "    prop_dict = {}\n",
    "    kp, actual_descriptor = find_features(img)\n",
    "    for image_path in dataset:\n",
    "        print(image_path)\n",
    "        image = cv.imread(image_path)\n",
    "        kp, actual_dataset_descriptor = find_features(image)\n",
    "        prop = calculate_proportion(actual_descriptor, actual_dataset_descriptor)\n",
    "        prop_dict[image_path] = prop\n",
    "    sorted_dict = [(k, prop_dict[k]) for k in sorted(prop_dict, key=prop_dict.get, reverse=True)]\n",
    "    return sorted_dict\n",
    "\n",
    "def display_5better(d):\n",
    "    for i in range(5):\n",
    "        print(f\"{d[i][0]} : {(d[i][1] * 100)}%\")\n",
    "        image = plt.imread(d[i][0])\n",
    "        plt.imshow(image)\n",
    "        plt.show()\n",
    "random.shuffle(DATASET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "random.shuffle(DATASET)\n",
    "img1 = cv.imread(\"./../BVW/PNGImages/Caltech_cars/image_0007.png\")\n",
    "d = compare_all_images(img1, DATASET[0:5])\n",
    "display_5better(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(DATASET)\n",
    "img1 = cv.imread(\"../BVW/PNGImages/Caltech_motorbikes_side/0163.png\")\n",
    "d = compare_all_images(img1, DATASET[0:5])\n",
    "display_5better(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(DATASET)\n",
    "img1 = cv.imread(\"../BVW/PNGImages/TUGraz_bike/bike_184.png\")\n",
    "d = compare_all_images(img1, DATASET[0:5])\n",
    "display_5better(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Meus comentários sobre os resultados aqui*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Faça agora uma busca usando uma imagem focada em um outro objeto qualquer e mostre as 3 imagens mais similares abaixo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(DATASET)\n",
    "img1 = cv.imread(\"../aula_17/101_ObjectCategories/gerenuk/image_0003.jpg\")\n",
    "d = compare_all_images(img1, DATASET[0:5])\n",
    "display_5better(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Meus comentários sobre os resultados aqui*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análise crítica e Revisão de conceitos\n",
    "\n",
    "Descreva com suas próprias palavras o quê são pontos de interesse e descritores.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pontos de interesse são pontos que diferem de grandes regiões comuns da imagem. Normalmente são bordas, cantos ou regiões com texturas.\n",
    "\n",
    "Descritores são objetos que descrevem características da vizinhança de um ponto de interesse da imagem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construimos uma abordagem que ordenou as três imagens testadas. Comente uma desvantagem desta abordagem. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uma desvantagem desta abordagem se encontra no fato de existir apenas um casamento por keypoint ou pela distância máxima precisar ser calibrada depois posteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
